{
  "slug": "neural-network",
  "name": "Neural Network",
  "categories": [
    "machinelearning"
  ],
  "body": {},
  "implementations": {
    "c-plus-plus": {
      "dir": "machine_learning\\neural_network.cpp",
      "url": "https://github.com/TheAlgorithms/c-plus-plus/tree/master/machine_learning\\neural_network.cpp",
      "code": "<span class=\"hljs-comment\">/**\r\n * @file\r\n * @author [Deep Raval](https://github.com/imdeep2905)\r\n *\r\n * @brief Implementation of [Multilayer Perceptron]\r\n * (https://en.wikipedia.org/wiki/Multilayer_perceptron).\r\n *\r\n * @details\r\n * A multilayer perceptron (MLP) is a class of feedforward artificial neural\r\n * network (ANN). The term MLP is used ambiguously, sometimes loosely to any\r\n * feedforward ANN, sometimes strictly to refer to networks composed of multiple\r\n * layers of perceptrons (with threshold activation). Multilayer perceptrons are\r\n * sometimes colloquially referred to as &quot;vanilla&quot; neural networks, especially\r\n * when they have a single hidden layer.\r\n *\r\n * An MLP consists of at least three layers of nodes: an input layer, a hidden\r\n * layer and an output layer. Except for the input nodes, each node is a neuron\r\n * that uses a nonlinear activation function. MLP utilizes a supervised learning\r\n * technique called backpropagation for training. Its multiple layers and\r\n * non-linear activation distinguish MLP from a linear perceptron. It can\r\n * distinguish data that is not linearly separable.\r\n *\r\n * See [Backpropagation](https://en.wikipedia.org/wiki/Backpropagation) for\r\n * training algorithm.\r\n *\r\n * \\note This implementation uses mini-batch gradient descent as optimizer and\r\n * MSE as loss function. Bias is also not included.\r\n */</span>\r\n\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;algorithm&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;cassert&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;chrono&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;cmath&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;fstream&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;sstream&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;string&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;valarray&gt;</span></span>\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span>\r\n\r\n<span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&quot;vector_ops.hpp&quot;</span>  <span class=\"hljs-comment\">// Custom header file for vector operations</span></span>\r\n\r\n<span class=\"hljs-comment\">/** \\namespace machine_learning\r\n * \\brief Machine learning algorithms\r\n */</span>\r\n<span class=\"hljs-keyword\">namespace</span> machine_learning {\r\n<span class=\"hljs-comment\">/** \\namespace neural_network\r\n * \\brief Neural Network or Multilayer Perceptron\r\n */</span>\r\n<span class=\"hljs-keyword\">namespace</span> neural_network {\r\n<span class=\"hljs-comment\">/** \\namespace activations\r\n * \\brief Various activation functions used in Neural network\r\n */</span>\r\n<span class=\"hljs-keyword\">namespace</span> activations {\r\n<span class=\"hljs-comment\">/**\r\n * Sigmoid function\r\n * @param X Value\r\n * @return Returns sigmoid(x)\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">sigmoid</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1.0</span> / (<span class=\"hljs-number\">1.0</span> + std::<span class=\"hljs-built_in\">exp</span>(-x)); }\r\n\r\n<span class=\"hljs-comment\">/**\r\n * Derivative of sigmoid function\r\n * @param X Value\r\n * @return Returns derivative of sigmoid(x)\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">dsigmoid</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x * (<span class=\"hljs-number\">1</span> - x); }\r\n\r\n<span class=\"hljs-comment\">/**\r\n * Relu function\r\n * @param X Value\r\n * @returns relu(x)\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">relu</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">max</span>(<span class=\"hljs-number\">0.0</span>, x); }\r\n\r\n<span class=\"hljs-comment\">/**\r\n * Derivative of relu function\r\n * @param X Value\r\n * @returns derivative of relu(x)\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">drelu</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x &gt;= <span class=\"hljs-number\">0.0</span> ? <span class=\"hljs-number\">1.0</span> : <span class=\"hljs-number\">0.0</span>; }\r\n\r\n<span class=\"hljs-comment\">/**\r\n * Tanh function\r\n * @param X Value\r\n * @return Returns tanh(x)\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">tanh</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">2</span> / (<span class=\"hljs-number\">1</span> + std::<span class=\"hljs-built_in\">exp</span>(<span class=\"hljs-number\">-2</span> * x)) - <span class=\"hljs-number\">1</span>; }\r\n\r\n<span class=\"hljs-comment\">/**\r\n * Derivative of Sigmoid function\r\n * @param X Value\r\n * @return Returns derivative of tanh(x)\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">dtanh</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> - x * x; }\r\n}  <span class=\"hljs-comment\">// namespace activations</span>\r\n<span class=\"hljs-comment\">/** \\namespace util_functions\r\n * \\brief Various utility functions used in Neural network\r\n */</span>\r\n<span class=\"hljs-keyword\">namespace</span> util_functions {\r\n<span class=\"hljs-comment\">/**\r\n * Square function\r\n * @param X Value\r\n * @return Returns x * x\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">square</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x * x; }\r\n<span class=\"hljs-comment\">/**\r\n * Identity function\r\n * @param X Value\r\n * @return Returns x\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">double</span> <span class=\"hljs-title\">identity_function</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;x)</span> </span>{ <span class=\"hljs-keyword\">return</span> x; }\r\n}  <span class=\"hljs-comment\">// namespace util_functions</span>\r\n<span class=\"hljs-comment\">/** \\namespace layers\r\n * \\brief This namespace contains layers used\r\n * in MLP.\r\n */</span>\r\n<span class=\"hljs-keyword\">namespace</span> layers {\r\n<span class=\"hljs-comment\">/**\r\n * neural_network::layers::DenseLayer class is used to store all necessary\r\n * information about the layers (i.e. neurons, activation and kernel). This\r\n * class is used by NeuralNetwork class to store layers.\r\n *\r\n */</span>\r\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DenseLayer</span> {\r\n <span class=\"hljs-keyword\">public</span>:\r\n    <span class=\"hljs-comment\">// To store activation function and it&#x27;s derivative</span>\r\n    <span class=\"hljs-built_in\">double</span> (*activation_function)(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;);\r\n    <span class=\"hljs-built_in\">double</span> (*dactivation_function)(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;);\r\n    <span class=\"hljs-type\">int</span> neurons;             <span class=\"hljs-comment\">// To store number of neurons (used in summary)</span>\r\n    std::string activation;  <span class=\"hljs-comment\">// To store activation name (used in summary)</span>\r\n    std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; kernel;  <span class=\"hljs-comment\">// To store kernel (aka weights)</span>\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Constructor for neural_network::layers::DenseLayer class\r\n     * @param neurons number of neurons\r\n     * @param activation activation function for layer\r\n     * @param kernel_shape shape of kernel\r\n     * @param random_kernel flag for whether to intialize kernel randomly\r\n     */</span>\r\n    <span class=\"hljs-built_in\">DenseLayer</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> &amp;neurons, <span class=\"hljs-type\">const</span> std::string &amp;activation,\r\n               <span class=\"hljs-type\">const</span> std::pair&lt;<span class=\"hljs-type\">size_t</span>, <span class=\"hljs-type\">size_t</span>&gt; &amp;kernel_shape,\r\n               <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;random_kernel) {\r\n        <span class=\"hljs-comment\">// Choosing activation (and it&#x27;s derivative)</span>\r\n        <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;sigmoid&quot;</span>) {\r\n            activation_function = neural_network::activations::sigmoid;\r\n            dactivation_function = neural_network::activations::sigmoid;\r\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;relu&quot;</span>) {\r\n            activation_function = neural_network::activations::relu;\r\n            dactivation_function = neural_network::activations::drelu;\r\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;tanh&quot;</span>) {\r\n            activation_function = neural_network::activations::tanh;\r\n            dactivation_function = neural_network::activations::dtanh;\r\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;none&quot;</span>) {\r\n            <span class=\"hljs-comment\">// Set identity function in casse of none is supplied</span>\r\n            activation_function =\r\n                neural_network::util_functions::identity_function;\r\n            dactivation_function =\r\n                neural_network::util_functions::identity_function;\r\n        } <span class=\"hljs-keyword\">else</span> {\r\n            <span class=\"hljs-comment\">// If supplied activation is invalid</span>\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid argument. Expected {none, sigmoid, relu, &quot;</span>\r\n                         <span class=\"hljs-string\">&quot;tanh} got &quot;</span>;\r\n            std::cerr &lt;&lt; activation &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        <span class=\"hljs-keyword\">this</span>-&gt;activation = activation;  <span class=\"hljs-comment\">// Setting activation name</span>\r\n        <span class=\"hljs-keyword\">this</span>-&gt;neurons = neurons;        <span class=\"hljs-comment\">// Setting number of neurons</span>\r\n        <span class=\"hljs-comment\">// Initialize kernel according to flag</span>\r\n        <span class=\"hljs-keyword\">if</span> (random_kernel) {\r\n            <span class=\"hljs-built_in\">uniform_random_initialization</span>(kernel, kernel_shape, <span class=\"hljs-number\">-1.0</span>, <span class=\"hljs-number\">1.0</span>);\r\n        } <span class=\"hljs-keyword\">else</span> {\r\n            <span class=\"hljs-built_in\">unit_matrix_initialization</span>(kernel, kernel_shape);\r\n        }\r\n    }\r\n    <span class=\"hljs-comment\">/**\r\n     * Constructor for neural_network::layers::DenseLayer class\r\n     * @param neurons number of neurons\r\n     * @param activation activation function for layer\r\n     * @param kernel values of kernel (useful in loading model)\r\n     */</span>\r\n    <span class=\"hljs-built_in\">DenseLayer</span>(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> &amp;neurons, <span class=\"hljs-type\">const</span> std::string &amp;activation,\r\n               <span class=\"hljs-type\">const</span> std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; &amp;kernel) {\r\n        <span class=\"hljs-comment\">// Choosing activation (and it&#x27;s derivative)</span>\r\n        <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;sigmoid&quot;</span>) {\r\n            activation_function = neural_network::activations::sigmoid;\r\n            dactivation_function = neural_network::activations::sigmoid;\r\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;relu&quot;</span>) {\r\n            activation_function = neural_network::activations::relu;\r\n            dactivation_function = neural_network::activations::drelu;\r\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;tanh&quot;</span>) {\r\n            activation_function = neural_network::activations::tanh;\r\n            dactivation_function = neural_network::activations::dtanh;\r\n        } <span class=\"hljs-keyword\">else</span> <span class=\"hljs-keyword\">if</span> (activation == <span class=\"hljs-string\">&quot;none&quot;</span>) {\r\n            <span class=\"hljs-comment\">// Set identity function in casse of none is supplied</span>\r\n            activation_function =\r\n                neural_network::util_functions::identity_function;\r\n            dactivation_function =\r\n                neural_network::util_functions::identity_function;\r\n        } <span class=\"hljs-keyword\">else</span> {\r\n            <span class=\"hljs-comment\">// If supplied activation is invalid</span>\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid argument. Expected {none, sigmoid, relu, &quot;</span>\r\n                         <span class=\"hljs-string\">&quot;tanh} got &quot;</span>;\r\n            std::cerr &lt;&lt; activation &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        <span class=\"hljs-keyword\">this</span>-&gt;activation = activation;  <span class=\"hljs-comment\">// Setting activation name</span>\r\n        <span class=\"hljs-keyword\">this</span>-&gt;neurons = neurons;        <span class=\"hljs-comment\">// Setting number of neurons</span>\r\n        <span class=\"hljs-keyword\">this</span>-&gt;kernel = kernel;          <span class=\"hljs-comment\">// Setting supplied kernel values</span>\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Copy Constructor for class DenseLayer.\r\n     *\r\n     * @param model instance of class to be copied.\r\n     */</span>\r\n    <span class=\"hljs-built_in\">DenseLayer</span>(<span class=\"hljs-type\">const</span> DenseLayer &amp;layer) = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Destructor for class DenseLayer.\r\n     */</span>\r\n    ~<span class=\"hljs-built_in\">DenseLayer</span>() = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Copy assignment operator for class DenseLayer\r\n     */</span>\r\n    DenseLayer &amp;<span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> DenseLayer &amp;layer) = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Move constructor for class DenseLayer\r\n     */</span>\r\n    <span class=\"hljs-built_in\">DenseLayer</span>(DenseLayer &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Move assignment operator for class DenseLayer\r\n     */</span>\r\n    DenseLayer &amp;<span class=\"hljs-keyword\">operator</span>=(DenseLayer &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\r\n};\r\n}  <span class=\"hljs-comment\">// namespace layers</span>\r\n<span class=\"hljs-comment\">/**\r\n * NeuralNetwork class is implements MLP. This class is\r\n * used by actual user to create and train networks.\r\n *\r\n */</span>\r\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">NeuralNetwork</span> {\r\n <span class=\"hljs-keyword\">private</span>:\r\n    std::vector&lt;neural_network::layers::DenseLayer&gt; layers;  <span class=\"hljs-comment\">// To store layers</span>\r\n    <span class=\"hljs-comment\">/**\r\n     * Private Constructor for class NeuralNetwork. This constructor\r\n     * is used internally to load model.\r\n     * @param config vector containing pair (neurons, activation)\r\n     * @param kernels vector containing all pretrained kernels\r\n     */</span>\r\n    <span class=\"hljs-built_in\">NeuralNetwork</span>(\r\n        <span class=\"hljs-type\">const</span> std::vector&lt;std::pair&lt;<span class=\"hljs-type\">int</span>, std::string&gt;&gt; &amp;config,\r\n        <span class=\"hljs-type\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;kernels) {\r\n        <span class=\"hljs-comment\">// First layer should not have activation</span>\r\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">begin</span>()-&gt;second != <span class=\"hljs-string\">&quot;none&quot;</span>) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr\r\n                &lt;&lt; <span class=\"hljs-string\">&quot;First layer can&#x27;t have activation other than none got &quot;</span>\r\n                &lt;&lt; config.<span class=\"hljs-built_in\">begin</span>()-&gt;second;\r\n            std::cerr &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        <span class=\"hljs-comment\">// Network should have atleast two layers</span>\r\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">size</span>() &lt;= <span class=\"hljs-number\">1</span>) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid size of network, &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Atleast two layers are required&quot;</span>;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        <span class=\"hljs-comment\">// Reconstructing all pretrained layers</span>\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; config.<span class=\"hljs-built_in\">size</span>(); i++) {\r\n            layers.<span class=\"hljs-built_in\">emplace_back</span>(neural_network::layers::<span class=\"hljs-built_in\">DenseLayer</span>(\r\n                config[i].first, config[i].second, kernels[i]));\r\n        }\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Network constructed successfully&quot;</span> &lt;&lt; std::endl;\r\n    }\r\n    <span class=\"hljs-comment\">/**\r\n     * Private function to get detailed predictions (i.e.\r\n     * activated neuron values). This function is used in\r\n     * backpropagation, single predict and batch predict.\r\n     * @param X input vector\r\n     */</span>\r\n    std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;\r\n    __detailed_single_prediction(<span class=\"hljs-type\">const</span> std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; &amp;X) {\r\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; details;\r\n        std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; current_pass = X;\r\n        details.<span class=\"hljs-built_in\">emplace_back</span>(X);\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;l : layers) {\r\n            current_pass = <span class=\"hljs-built_in\">multiply</span>(current_pass, l.kernel);\r\n            current_pass = <span class=\"hljs-built_in\">apply_function</span>(current_pass, l.activation_function);\r\n            details.<span class=\"hljs-built_in\">emplace_back</span>(current_pass);\r\n        }\r\n        <span class=\"hljs-keyword\">return</span> details;\r\n    }\r\n\r\n <span class=\"hljs-keyword\">public</span>:\r\n    <span class=\"hljs-comment\">/**\r\n     * Default Constructor for class NeuralNetwork. This constructor\r\n     * is used to create empty variable of type NeuralNetwork class.\r\n     */</span>\r\n    <span class=\"hljs-built_in\">NeuralNetwork</span>() = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Constructor for class NeuralNetwork. This constructor\r\n     * is used by user.\r\n     * @param config vector containing pair (neurons, activation)\r\n     */</span>\r\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">explicit</span> <span class=\"hljs-title\">NeuralNetwork</span><span class=\"hljs-params\">(\r\n        <span class=\"hljs-type\">const</span> std::vector&lt;std::pair&lt;<span class=\"hljs-type\">int</span>, std::string&gt;&gt; &amp;config)</span> </span>{\r\n        <span class=\"hljs-comment\">// First layer should not have activation</span>\r\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">begin</span>()-&gt;second != <span class=\"hljs-string\">&quot;none&quot;</span>) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr\r\n                &lt;&lt; <span class=\"hljs-string\">&quot;First layer can&#x27;t have activation other than none got &quot;</span>\r\n                &lt;&lt; config.<span class=\"hljs-built_in\">begin</span>()-&gt;second;\r\n            std::cerr &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        <span class=\"hljs-comment\">// Network should have atleast two layers</span>\r\n        <span class=\"hljs-keyword\">if</span> (config.<span class=\"hljs-built_in\">size</span>() &lt;= <span class=\"hljs-number\">1</span>) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Invalid size of network, &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Atleast two layers are required&quot;</span>;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        <span class=\"hljs-comment\">// Separately creating first layer so it can have unit matrix</span>\r\n        <span class=\"hljs-comment\">// as kernel.</span>\r\n        layers.<span class=\"hljs-built_in\">push_back</span>(neural_network::layers::<span class=\"hljs-built_in\">DenseLayer</span>(\r\n            config[<span class=\"hljs-number\">0</span>].first, config[<span class=\"hljs-number\">0</span>].second,\r\n            {config[<span class=\"hljs-number\">0</span>].first, config[<span class=\"hljs-number\">0</span>].first}, <span class=\"hljs-literal\">false</span>));\r\n        <span class=\"hljs-comment\">// Creating remaining layers</span>\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">1</span>; i &lt; config.<span class=\"hljs-built_in\">size</span>(); i++) {\r\n            layers.<span class=\"hljs-built_in\">push_back</span>(neural_network::layers::<span class=\"hljs-built_in\">DenseLayer</span>(\r\n                config[i].first, config[i].second,\r\n                {config[i - <span class=\"hljs-number\">1</span>].first, config[i].first}, <span class=\"hljs-literal\">true</span>));\r\n        }\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Network constructed successfully&quot;</span> &lt;&lt; std::endl;\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Copy Constructor for class NeuralNetwork.\r\n     *\r\n     * @param model instance of class to be copied.\r\n     */</span>\r\n    <span class=\"hljs-built_in\">NeuralNetwork</span>(<span class=\"hljs-type\">const</span> NeuralNetwork &amp;model) = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Destructor for class NeuralNetwork.\r\n     */</span>\r\n    ~<span class=\"hljs-built_in\">NeuralNetwork</span>() = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Copy assignment operator for class NeuralNetwork\r\n     */</span>\r\n    NeuralNetwork &amp;<span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> NeuralNetwork &amp;model) = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Move constructor for class NeuralNetwork\r\n     */</span>\r\n    <span class=\"hljs-built_in\">NeuralNetwork</span>(NeuralNetwork &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Move assignment operator for class NeuralNetwork\r\n     */</span>\r\n    NeuralNetwork &amp;<span class=\"hljs-keyword\">operator</span>=(NeuralNetwork &amp;&amp;) = <span class=\"hljs-keyword\">default</span>;\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to get X and Y from csv file (where X = data, Y = label)\r\n     * @param file_name csv file name\r\n     * @param last_label flag for whether label is in first or last column\r\n     * @param normalize flag for whether to normalize data\r\n     * @param slip_lines number of lines to skip\r\n     * @return returns pair of X and Y\r\n     */</span>\r\n    std::pair&lt;std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;,\r\n              std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;&gt;\r\n    <span class=\"hljs-built_in\">get_XY_from_csv</span>(<span class=\"hljs-type\">const</span> std::string &amp;file_name, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;last_label,\r\n                    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;normalize, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> &amp;slip_lines = <span class=\"hljs-number\">1</span>) {\r\n        std::ifstream in_file;                          <span class=\"hljs-comment\">// Ifstream to read file</span>\r\n        in_file.<span class=\"hljs-built_in\">open</span>(file_name.<span class=\"hljs-built_in\">c_str</span>(), std::ios::in);  <span class=\"hljs-comment\">// Open file</span>\r\n        <span class=\"hljs-comment\">// If there is any problem in opening file</span>\r\n        <span class=\"hljs-keyword\">if</span> (!in_file.<span class=\"hljs-built_in\">is_open</span>()) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Unable to open file: &quot;</span> &lt;&lt; file_name &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; X,\r\n            Y;             <span class=\"hljs-comment\">// To store X and Y</span>\r\n        std::string line;  <span class=\"hljs-comment\">// To store each line</span>\r\n        <span class=\"hljs-comment\">// Skip lines</span>\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> i = <span class=\"hljs-number\">0</span>; i &lt; slip_lines; i++) {\r\n            std::<span class=\"hljs-built_in\">getline</span>(in_file, line, <span class=\"hljs-string\">&#x27;\\n&#x27;</span>);  <span class=\"hljs-comment\">// Ignore line</span>\r\n        }\r\n        <span class=\"hljs-comment\">// While file has information</span>\r\n        <span class=\"hljs-keyword\">while</span> (!in_file.<span class=\"hljs-built_in\">eof</span>() &amp;&amp; std::<span class=\"hljs-built_in\">getline</span>(in_file, line, <span class=\"hljs-string\">&#x27;\\n&#x27;</span>)) {\r\n            std::valarray&lt;<span class=\"hljs-type\">double</span>&gt; x_data,\r\n                y_data;                  <span class=\"hljs-comment\">// To store single sample and label</span>\r\n            <span class=\"hljs-function\">std::stringstream <span class=\"hljs-title\">ss</span><span class=\"hljs-params\">(line)</span></span>;  <span class=\"hljs-comment\">// Constructing stringstream from line</span>\r\n            std::string token;  <span class=\"hljs-comment\">// To store each token in line (seprated by &#x27;,&#x27;)</span>\r\n            <span class=\"hljs-keyword\">while</span> (std::<span class=\"hljs-built_in\">getline</span>(ss, token, <span class=\"hljs-string\">&#x27;,&#x27;</span>)) {  <span class=\"hljs-comment\">// For each token</span>\r\n                <span class=\"hljs-comment\">// Insert numerical value of token in x_data</span>\r\n                x_data = <span class=\"hljs-built_in\">insert_element</span>(x_data, std::<span class=\"hljs-built_in\">stod</span>(token));\r\n            }\r\n            <span class=\"hljs-comment\">// If label is in last column</span>\r\n            <span class=\"hljs-keyword\">if</span> (last_label) {\r\n                y_data.<span class=\"hljs-built_in\">resize</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">back</span>().neurons);\r\n                <span class=\"hljs-comment\">// If task is classification</span>\r\n                <span class=\"hljs-keyword\">if</span> (y_data.<span class=\"hljs-built_in\">size</span>() &gt; <span class=\"hljs-number\">1</span>) {\r\n                    y_data[x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>]] = <span class=\"hljs-number\">1</span>;\r\n                }\r\n                <span class=\"hljs-comment\">// If task is regrssion (of single value)</span>\r\n                <span class=\"hljs-keyword\">else</span> {\r\n                    y_data[<span class=\"hljs-number\">0</span>] = x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>];\r\n                }\r\n                x_data = <span class=\"hljs-built_in\">pop_back</span>(x_data);  <span class=\"hljs-comment\">// Remove label from x_data</span>\r\n            } <span class=\"hljs-keyword\">else</span> {\r\n                y_data.<span class=\"hljs-built_in\">resize</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">back</span>().neurons);\r\n                <span class=\"hljs-comment\">// If task is classification</span>\r\n                <span class=\"hljs-keyword\">if</span> (y_data.<span class=\"hljs-built_in\">size</span>() &gt; <span class=\"hljs-number\">1</span>) {\r\n                    y_data[x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>]] = <span class=\"hljs-number\">1</span>;\r\n                }\r\n                <span class=\"hljs-comment\">// If task is regrssion (of single value)</span>\r\n                <span class=\"hljs-keyword\">else</span> {\r\n                    y_data[<span class=\"hljs-number\">0</span>] = x_data[x_data.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>];\r\n                }\r\n                x_data = <span class=\"hljs-built_in\">pop_front</span>(x_data);  <span class=\"hljs-comment\">// Remove label from x_data</span>\r\n            }\r\n            <span class=\"hljs-comment\">// Push collected X_data and y_data in X and Y</span>\r\n            X.<span class=\"hljs-built_in\">push_back</span>({x_data});\r\n            Y.<span class=\"hljs-built_in\">push_back</span>({y_data});\r\n        }\r\n        <span class=\"hljs-comment\">// Normalize training data if flag is set</span>\r\n        <span class=\"hljs-keyword\">if</span> (normalize) {\r\n            <span class=\"hljs-comment\">// Scale data between 0 and 1 using min-max scaler</span>\r\n            X = <span class=\"hljs-built_in\">minmax_scaler</span>(X, <span class=\"hljs-number\">0.01</span>, <span class=\"hljs-number\">1.0</span>);\r\n        }\r\n        in_file.<span class=\"hljs-built_in\">close</span>();         <span class=\"hljs-comment\">// Closing file</span>\r\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">make_pair</span>(X, Y);  <span class=\"hljs-comment\">// Return pair of X and Y</span>\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to get prediction of model on single sample.\r\n     * @param X array of feature vectors\r\n     * @return returns predictions as vector\r\n     */</span>\r\n    std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; <span class=\"hljs-built_in\">single_predict</span>(\r\n        <span class=\"hljs-type\">const</span> std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; &amp;X) {\r\n        <span class=\"hljs-comment\">// Get activations of all layers</span>\r\n        <span class=\"hljs-keyword\">auto</span> activations = <span class=\"hljs-keyword\">this</span>-&gt;__detailed_single_prediction(X);\r\n        <span class=\"hljs-comment\">// Return activations of last layer (actual predicted values)</span>\r\n        <span class=\"hljs-keyword\">return</span> activations.<span class=\"hljs-built_in\">back</span>();\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to get prediction of model on batch\r\n     * @param X array of feature vectors\r\n     * @return returns predicted values as vector\r\n     */</span>\r\n    std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; <span class=\"hljs-built_in\">batch_predict</span>(\r\n        <span class=\"hljs-type\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;X) {\r\n        <span class=\"hljs-comment\">// Store predicted values</span>\r\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; <span class=\"hljs-built_in\">predicted_batch</span>(\r\n            X.<span class=\"hljs-built_in\">size</span>());\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; X.<span class=\"hljs-built_in\">size</span>(); i++) {  <span class=\"hljs-comment\">// For every sample</span>\r\n            <span class=\"hljs-comment\">// Push predicted values</span>\r\n            predicted_batch[i] = <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">single_predict</span>(X[i]);\r\n        }\r\n        <span class=\"hljs-keyword\">return</span> predicted_batch;  <span class=\"hljs-comment\">// Return predicted values</span>\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to fit model on supplied data\r\n     * @param X array of feature vectors\r\n     * @param Y array of target values\r\n     * @param epochs number of epochs (default = 100)\r\n     * @param learning_rate learning rate (default = 0.01)\r\n     * @param batch_size batch size for gradient descent (default = 32)\r\n     * @param shuffle flag for whether to shuffle data (default = true)\r\n     */</span>\r\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">fit</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;X_,\r\n             <span class=\"hljs-type\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;Y_,\r\n             <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> &amp;epochs = <span class=\"hljs-number\">100</span>, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;learning_rate = <span class=\"hljs-number\">0.01</span>,\r\n             <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">size_t</span> &amp;batch_size = <span class=\"hljs-number\">32</span>, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;shuffle = <span class=\"hljs-literal\">true</span>)</span> </span>{\r\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; X = X_, Y = Y_;\r\n        <span class=\"hljs-comment\">// Both label and input data should have same size</span>\r\n        <span class=\"hljs-keyword\">if</span> (X.<span class=\"hljs-built_in\">size</span>() != Y.<span class=\"hljs-built_in\">size</span>()) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;X and Y in fit have different sizes&quot;</span> &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Training Started&quot;</span> &lt;&lt; std::endl;\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">int</span> epoch = <span class=\"hljs-number\">1</span>; epoch &lt;= epochs; epoch++) {  <span class=\"hljs-comment\">// For every epoch</span>\r\n            <span class=\"hljs-comment\">// Shuffle X and Y if flag is set</span>\r\n            <span class=\"hljs-keyword\">if</span> (shuffle) {\r\n                <span class=\"hljs-built_in\">equal_shuffle</span>(X, Y);\r\n            }\r\n            <span class=\"hljs-keyword\">auto</span> start =\r\n                std::chrono::high_resolution_clock::<span class=\"hljs-built_in\">now</span>();  <span class=\"hljs-comment\">// Start clock</span>\r\n            <span class=\"hljs-type\">double</span> loss = <span class=\"hljs-number\">0</span>,\r\n                   acc = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// Intialize performance metrics with zero</span>\r\n            <span class=\"hljs-comment\">// For each starting index of batch</span>\r\n            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> batch_start = <span class=\"hljs-number\">0</span>; batch_start &lt; X.<span class=\"hljs-built_in\">size</span>();\r\n                 batch_start += batch_size) {\r\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = batch_start;\r\n                     i &lt; std::<span class=\"hljs-built_in\">min</span>(X.<span class=\"hljs-built_in\">size</span>(), batch_start + batch_size); i++) {\r\n                    std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; grad, cur_error,\r\n                        predicted;\r\n                    <span class=\"hljs-keyword\">auto</span> activations = <span class=\"hljs-keyword\">this</span>-&gt;__detailed_single_prediction(X[i]);\r\n                    <span class=\"hljs-comment\">// Gradients vector to store gradients for all layers</span>\r\n                    <span class=\"hljs-comment\">// They will be averaged and applied to kernel</span>\r\n                    std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; gradients;\r\n                    gradients.<span class=\"hljs-built_in\">resize</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">size</span>());\r\n                    <span class=\"hljs-comment\">// First intialize gradients to zero</span>\r\n                    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; gradients.<span class=\"hljs-built_in\">size</span>(); i++) {\r\n                        <span class=\"hljs-built_in\">zeroes_initialization</span>(\r\n                            gradients[i], <span class=\"hljs-built_in\">get_shape</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers[i].kernel));\r\n                    }\r\n                    predicted = activations.<span class=\"hljs-built_in\">back</span>();  <span class=\"hljs-comment\">// Predicted vector</span>\r\n                    cur_error = predicted - Y[i];    <span class=\"hljs-comment\">// Absoulute error</span>\r\n                    <span class=\"hljs-comment\">// Calculating loss with MSE</span>\r\n                    loss += <span class=\"hljs-built_in\">sum</span>(<span class=\"hljs-built_in\">apply_function</span>(\r\n                        cur_error, neural_network::util_functions::square));\r\n                    <span class=\"hljs-comment\">// If prediction is correct</span>\r\n                    <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">argmax</span>(predicted) == <span class=\"hljs-built_in\">argmax</span>(Y[i])) {\r\n                        acc += <span class=\"hljs-number\">1</span>;\r\n                    }\r\n                    <span class=\"hljs-comment\">// For every layer (except first) starting from last one</span>\r\n                    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> j = <span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>; j &gt;= <span class=\"hljs-number\">1</span>; j--) {\r\n                        <span class=\"hljs-comment\">// Backpropogating errors</span>\r\n                        cur_error = <span class=\"hljs-built_in\">hadamard_product</span>(\r\n                            cur_error,\r\n                            <span class=\"hljs-built_in\">apply_function</span>(\r\n                                activations[j + <span class=\"hljs-number\">1</span>],\r\n                                <span class=\"hljs-keyword\">this</span>-&gt;layers[j].dactivation_function));\r\n                        <span class=\"hljs-comment\">// Calculating gradient for current layer</span>\r\n                        grad = <span class=\"hljs-built_in\">multiply</span>(<span class=\"hljs-built_in\">transpose</span>(activations[j]), cur_error);\r\n                        <span class=\"hljs-comment\">// Change error according to current kernel values</span>\r\n                        cur_error = <span class=\"hljs-built_in\">multiply</span>(cur_error,\r\n                                             <span class=\"hljs-built_in\">transpose</span>(<span class=\"hljs-keyword\">this</span>-&gt;layers[j].kernel));\r\n                        <span class=\"hljs-comment\">// Adding gradient values to collection of gradients</span>\r\n                        gradients[j] = gradients[j] + grad / <span class=\"hljs-built_in\">double</span>(batch_size);\r\n                    }\r\n                    <span class=\"hljs-comment\">// Applying gradients</span>\r\n                    <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> j = <span class=\"hljs-keyword\">this</span>-&gt;layers.<span class=\"hljs-built_in\">size</span>() - <span class=\"hljs-number\">1</span>; j &gt;= <span class=\"hljs-number\">1</span>; j--) {\r\n                        <span class=\"hljs-comment\">// Updating kernel (aka weights)</span>\r\n                        <span class=\"hljs-keyword\">this</span>-&gt;layers[j].kernel = <span class=\"hljs-keyword\">this</span>-&gt;layers[j].kernel -\r\n                                                 gradients[j] * learning_rate;\r\n                    }\r\n                }\r\n            }\r\n            <span class=\"hljs-keyword\">auto</span> stop =\r\n                std::chrono::high_resolution_clock::<span class=\"hljs-built_in\">now</span>();  <span class=\"hljs-comment\">// Stoping the clock</span>\r\n            <span class=\"hljs-comment\">// Calculate time taken by epoch</span>\r\n            <span class=\"hljs-keyword\">auto</span> duration =\r\n                std::chrono::<span class=\"hljs-built_in\">duration_cast</span>&lt;std::chrono::microseconds&gt;(stop -\r\n                                                                      start);\r\n            loss /= X.<span class=\"hljs-built_in\">size</span>();        <span class=\"hljs-comment\">// Averaging loss</span>\r\n            acc /= X.<span class=\"hljs-built_in\">size</span>();         <span class=\"hljs-comment\">// Averaging accuracy</span>\r\n            std::cout.<span class=\"hljs-built_in\">precision</span>(<span class=\"hljs-number\">4</span>);  <span class=\"hljs-comment\">// set output precision to 4</span>\r\n            <span class=\"hljs-comment\">// Printing training stats</span>\r\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Training: Epoch &quot;</span> &lt;&lt; epoch &lt;&lt; <span class=\"hljs-string\">&#x27;/&#x27;</span> &lt;&lt; epochs;\r\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Loss: &quot;</span> &lt;&lt; loss;\r\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Accuracy: &quot;</span> &lt;&lt; acc;\r\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Taken time: &quot;</span> &lt;&lt; duration.<span class=\"hljs-built_in\">count</span>() / <span class=\"hljs-number\">1e6</span>\r\n                      &lt;&lt; <span class=\"hljs-string\">&quot; seconds&quot;</span>;\r\n            std::cout &lt;&lt; std::endl;\r\n        }\r\n        <span class=\"hljs-keyword\">return</span>;\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to fit model on data stored in csv file\r\n     * @param file_name csv file name\r\n     * @param last_label flag for whether label is in first or last column\r\n     * @param epochs number of epochs\r\n     * @param learning_rate learning rate\r\n     * @param normalize flag for whether to normalize data\r\n     * @param slip_lines number of lines to skip\r\n     * @param batch_size batch size for gradient descent (default = 32)\r\n     * @param shuffle flag for whether to shuffle data (default = true)\r\n     */</span>\r\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">fit_from_csv</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::string &amp;file_name, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;last_label,\r\n                      <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> &amp;epochs, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> &amp;learning_rate,\r\n                      <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;normalize, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> &amp;slip_lines = <span class=\"hljs-number\">1</span>,\r\n                      <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">size_t</span> &amp;batch_size = <span class=\"hljs-number\">32</span>,\r\n                      <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;shuffle = <span class=\"hljs-literal\">true</span>)</span> </span>{\r\n        <span class=\"hljs-comment\">// Getting training data from csv file</span>\r\n        <span class=\"hljs-keyword\">auto</span> data =\r\n            <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">get_XY_from_csv</span>(file_name, last_label, normalize, slip_lines);\r\n        <span class=\"hljs-comment\">// Fit the model on training data</span>\r\n        <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">fit</span>(data.first, data.second, epochs, learning_rate, batch_size,\r\n                  shuffle);\r\n        <span class=\"hljs-keyword\">return</span>;\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to evaluate model on supplied data\r\n     * @param X array of feature vectors (input data)\r\n     * @param Y array of target values (label)\r\n     */</span>\r\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">evaluate</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;X,\r\n                  <span class=\"hljs-type\">const</span> std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt; &amp;Y)</span> </span>{\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Evaluation Started&quot;</span> &lt;&lt; std::endl;\r\n        <span class=\"hljs-type\">double</span> acc = <span class=\"hljs-number\">0</span>, loss = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// intialize performance metrics with zero</span>\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; X.<span class=\"hljs-built_in\">size</span>(); i++) {  <span class=\"hljs-comment\">// For every sample in input</span>\r\n            <span class=\"hljs-comment\">// Get predictions</span>\r\n            std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; pred =\r\n                <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">single_predict</span>(X[i]);\r\n            <span class=\"hljs-comment\">// If predicted class is correct</span>\r\n            <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-built_in\">argmax</span>(pred) == <span class=\"hljs-built_in\">argmax</span>(Y[i])) {\r\n                acc += <span class=\"hljs-number\">1</span>;  <span class=\"hljs-comment\">// Increment accuracy</span>\r\n            }\r\n            <span class=\"hljs-comment\">// Calculating loss - Mean Squared Error</span>\r\n            loss += <span class=\"hljs-built_in\">sum</span>(<span class=\"hljs-built_in\">apply_function</span>((Y[i] - pred),\r\n                                       neural_network::util_functions::square) *\r\n                        <span class=\"hljs-number\">0.5</span>);\r\n        }\r\n        acc /= X.<span class=\"hljs-built_in\">size</span>();   <span class=\"hljs-comment\">// Averaging accuracy</span>\r\n        loss /= X.<span class=\"hljs-built_in\">size</span>();  <span class=\"hljs-comment\">// Averaging loss</span>\r\n        <span class=\"hljs-comment\">// Prinitng performance of the model</span>\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Evaluation: Loss: &quot;</span> &lt;&lt; loss;\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Accuracy: &quot;</span> &lt;&lt; acc &lt;&lt; std::endl;\r\n        <span class=\"hljs-keyword\">return</span>;\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to evaluate model on data stored in csv file\r\n     * @param file_name csv file name\r\n     * @param last_label flag for whether label is in first or last column\r\n     * @param normalize flag for whether to normalize data\r\n     * @param slip_lines number of lines to skip\r\n     */</span>\r\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">evaluate_from_csv</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::string &amp;file_name, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;last_label,\r\n                           <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">bool</span> &amp;normalize, <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> &amp;slip_lines = <span class=\"hljs-number\">1</span>)</span> </span>{\r\n        <span class=\"hljs-comment\">// Getting training data from csv file</span>\r\n        <span class=\"hljs-keyword\">auto</span> data =\r\n            <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">get_XY_from_csv</span>(file_name, last_label, normalize, slip_lines);\r\n        <span class=\"hljs-comment\">// Evaluating model</span>\r\n        <span class=\"hljs-keyword\">this</span>-&gt;<span class=\"hljs-built_in\">evaluate</span>(data.first, data.second);\r\n        <span class=\"hljs-keyword\">return</span>;\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to save current model.\r\n     * @param file_name file name to save model (*.model)\r\n     */</span>\r\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">save_model</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::string &amp;_file_name)</span> </span>{\r\n        std::string file_name = _file_name;\r\n        <span class=\"hljs-comment\">// Adding &quot;.model&quot; extension if it is not already there in name</span>\r\n        <span class=\"hljs-keyword\">if</span> (file_name.<span class=\"hljs-built_in\">find</span>(<span class=\"hljs-string\">&quot;.model&quot;</span>) == file_name.npos) {\r\n            file_name += <span class=\"hljs-string\">&quot;.model&quot;</span>;\r\n        }\r\n        std::ofstream out_file;  <span class=\"hljs-comment\">// Ofstream to write in file</span>\r\n        <span class=\"hljs-comment\">// Open file in out|trunc mode</span>\r\n        out_file.<span class=\"hljs-built_in\">open</span>(file_name.<span class=\"hljs-built_in\">c_str</span>(),\r\n                      std::ofstream::out | std::ofstream::trunc);\r\n        <span class=\"hljs-comment\">// If there is any problem in opening file</span>\r\n        <span class=\"hljs-keyword\">if</span> (!out_file.<span class=\"hljs-built_in\">is_open</span>()) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Unable to open file: &quot;</span> &lt;&lt; file_name &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        <span class=\"hljs-comment\">/**\r\n            Format in which model is saved:\r\n\r\n            total_layers\r\n            neurons(1st neural_network::layers::DenseLayer) activation_name(1st\r\n           neural_network::layers::DenseLayer) kernel_shape(1st\r\n           neural_network::layers::DenseLayer) kernel_values\r\n            .\r\n            .\r\n            .\r\n            neurons(Nth neural_network::layers::DenseLayer) activation_name(Nth\r\n           neural_network::layers::DenseLayer) kernel_shape(Nth\r\n           neural_network::layers::DenseLayer) kernel_value\r\n\r\n            For Example, pretrained model with 3 layers:\r\n            &lt;pre&gt;\r\n            3\r\n            4 none\r\n            4 4\r\n            1 0 0 0\r\n            0 1 0 0\r\n            0 0 1 0\r\n            0 0 0 1\r\n            6 relu\r\n            4 6\r\n            -1.88963 -3.61165 1.30757 -0.443906 -2.41039 -2.69653\r\n            -0.684753 0.0891452 0.795294 -2.39619 2.73377 0.318202\r\n            -2.91451 -4.43249 -0.804187 2.51995 -6.97524 -1.07049\r\n            -0.571531 -1.81689 -1.24485 1.92264 -2.81322 1.01741\r\n            3 sigmoid\r\n            6 3\r\n            0.390267 -0.391703 -0.0989607\r\n            0.499234 -0.564539 -0.28097\r\n            0.553386 -0.153974 -1.92493\r\n            -2.01336 -0.0219682 1.44145\r\n            1.72853 -0.465264 -0.705373\r\n            -0.908409 -0.740547 0.376416\r\n            &lt;/pre&gt;\r\n        */</span>\r\n        <span class=\"hljs-comment\">// Saving model in the same format</span>\r\n        out_file &lt;&lt; layers.<span class=\"hljs-built_in\">size</span>();\r\n        out_file &lt;&lt; std::endl;\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;layer : <span class=\"hljs-keyword\">this</span>-&gt;layers) {\r\n            out_file &lt;&lt; layer.neurons &lt;&lt; <span class=\"hljs-string\">&#x27; &#x27;</span> &lt;&lt; layer.activation &lt;&lt; std::endl;\r\n            <span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> shape = <span class=\"hljs-built_in\">get_shape</span>(layer.kernel);\r\n            out_file &lt;&lt; shape.first &lt;&lt; <span class=\"hljs-string\">&#x27; &#x27;</span> &lt;&lt; shape.second &lt;&lt; std::endl;\r\n            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;row : layer.kernel) {\r\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">const</span> <span class=\"hljs-keyword\">auto</span> &amp;val : row) {\r\n                    out_file &lt;&lt; val &lt;&lt; <span class=\"hljs-string\">&#x27; &#x27;</span>;\r\n                }\r\n                out_file &lt;&lt; std::endl;\r\n            }\r\n        }\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Model saved successfully with name : &quot;</span>;\r\n        std::cout &lt;&lt; file_name &lt;&lt; std::endl;\r\n        out_file.<span class=\"hljs-built_in\">close</span>();  <span class=\"hljs-comment\">// Closing file</span>\r\n        <span class=\"hljs-keyword\">return</span>;\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to load earlier saved model.\r\n     * @param file_name file from which model will be loaded (*.model)\r\n     * @return instance of NeuralNetwork class with pretrained weights\r\n     */</span>\r\n    <span class=\"hljs-function\">NeuralNetwork <span class=\"hljs-title\">load_model</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> std::string &amp;file_name)</span> </span>{\r\n        std::ifstream in_file;            <span class=\"hljs-comment\">// Ifstream to read file</span>\r\n        in_file.<span class=\"hljs-built_in\">open</span>(file_name.<span class=\"hljs-built_in\">c_str</span>());  <span class=\"hljs-comment\">// Openinig file</span>\r\n        <span class=\"hljs-comment\">// If there is any problem in opening file</span>\r\n        <span class=\"hljs-keyword\">if</span> (!in_file.<span class=\"hljs-built_in\">is_open</span>()) {\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;ERROR (&quot;</span> &lt;&lt; __func__ &lt;&lt; <span class=\"hljs-string\">&quot;) : &quot;</span>;\r\n            std::cerr &lt;&lt; <span class=\"hljs-string\">&quot;Unable to open file: &quot;</span> &lt;&lt; file_name &lt;&lt; std::endl;\r\n            std::<span class=\"hljs-built_in\">exit</span>(EXIT_FAILURE);\r\n        }\r\n        std::vector&lt;std::pair&lt;<span class=\"hljs-type\">int</span>, std::string&gt;&gt; config;  <span class=\"hljs-comment\">// To store config</span>\r\n        std::vector&lt;std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt;&gt;\r\n            kernels;  <span class=\"hljs-comment\">// To store pretrained kernels</span>\r\n        <span class=\"hljs-comment\">// Loading model from saved file format</span>\r\n        <span class=\"hljs-type\">size_t</span> total_layers = <span class=\"hljs-number\">0</span>;\r\n        in_file &gt;&gt; total_layers;\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">0</span>; i &lt; total_layers; i++) {\r\n            <span class=\"hljs-type\">int</span> neurons = <span class=\"hljs-number\">0</span>;\r\n            std::string activation;\r\n            <span class=\"hljs-type\">size_t</span> shape_a = <span class=\"hljs-number\">0</span>, shape_b = <span class=\"hljs-number\">0</span>;\r\n            std::vector&lt;std::valarray&lt;<span class=\"hljs-type\">double</span>&gt;&gt; kernel;\r\n            in_file &gt;&gt; neurons &gt;&gt; activation &gt;&gt; shape_a &gt;&gt; shape_b;\r\n            <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> r = <span class=\"hljs-number\">0</span>; r &lt; shape_a; r++) {\r\n                <span class=\"hljs-function\">std::valarray&lt;<span class=\"hljs-type\">double</span>&gt; <span class=\"hljs-title\">row</span><span class=\"hljs-params\">(shape_b)</span></span>;\r\n                <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> c = <span class=\"hljs-number\">0</span>; c &lt; shape_b; c++) {\r\n                    in_file &gt;&gt; row[c];\r\n                }\r\n                kernel.<span class=\"hljs-built_in\">push_back</span>(row);\r\n            }\r\n            config.<span class=\"hljs-built_in\">emplace_back</span>(<span class=\"hljs-built_in\">make_pair</span>(neurons, activation));\r\n            ;\r\n            kernels.<span class=\"hljs-built_in\">emplace_back</span>(kernel);\r\n        }\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;INFO: Model loaded successfully&quot;</span> &lt;&lt; std::endl;\r\n        in_file.<span class=\"hljs-built_in\">close</span>();  <span class=\"hljs-comment\">// Closing file</span>\r\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-built_in\">NeuralNetwork</span>(\r\n            config, kernels);  <span class=\"hljs-comment\">// Return instance of NeuralNetwork class</span>\r\n    }\r\n\r\n    <span class=\"hljs-comment\">/**\r\n     * Function to print summary of the network.\r\n     */</span>\r\n    <span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">summary</span><span class=\"hljs-params\">()</span> </span>{\r\n        <span class=\"hljs-comment\">// Printing Summary</span>\r\n        std::cout\r\n            &lt;&lt; <span class=\"hljs-string\">&quot;===============================================================&quot;</span>\r\n            &lt;&lt; std::endl;\r\n        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;\\t\\t+ MODEL SUMMARY +\\t\\t\\n&quot;</span>;\r\n        std::cout\r\n            &lt;&lt; <span class=\"hljs-string\">&quot;===============================================================&quot;</span>\r\n            &lt;&lt; std::endl;\r\n        <span class=\"hljs-keyword\">for</span> (<span class=\"hljs-type\">size_t</span> i = <span class=\"hljs-number\">1</span>; i &lt;= layers.<span class=\"hljs-built_in\">size</span>(); i++) {  <span class=\"hljs-comment\">// For every layer</span>\r\n            std::cout &lt;&lt; i &lt;&lt; <span class=\"hljs-string\">&quot;)&quot;</span>;\r\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot; Neurons : &quot;</span>\r\n                      &lt;&lt; layers[i - <span class=\"hljs-number\">1</span>].neurons;  <span class=\"hljs-comment\">// number of neurons</span>\r\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, Activation : &quot;</span>\r\n                      &lt;&lt; layers[i - <span class=\"hljs-number\">1</span>].activation;  <span class=\"hljs-comment\">// activation</span>\r\n            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;, kernel Shape : &quot;</span>\r\n                      &lt;&lt; <span class=\"hljs-built_in\">get_shape</span>(layers[i - <span class=\"hljs-number\">1</span>].kernel);  <span class=\"hljs-comment\">// kernel shape</span>\r\n            std::cout &lt;&lt; std::endl;\r\n        }\r\n        std::cout\r\n            &lt;&lt; <span class=\"hljs-string\">&quot;===============================================================&quot;</span>\r\n            &lt;&lt; std::endl;\r\n        <span class=\"hljs-keyword\">return</span>;\r\n    }\r\n};\r\n}  <span class=\"hljs-comment\">// namespace neural_network</span>\r\n}  <span class=\"hljs-comment\">// namespace machine_learning</span>\r\n\r\n<span class=\"hljs-comment\">/**\r\n * Function to test neural network\r\n * @returns none\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">test</span><span class=\"hljs-params\">()</span> </span>{\r\n    <span class=\"hljs-comment\">// Creating network with 3 layers for &quot;iris.csv&quot;</span>\r\n    machine_learning::neural_network::NeuralNetwork myNN =\r\n        machine_learning::neural_network::<span class=\"hljs-built_in\">NeuralNetwork</span>({\r\n            {<span class=\"hljs-number\">4</span>, <span class=\"hljs-string\">&quot;none&quot;</span>},  <span class=\"hljs-comment\">// First layer with 3 neurons and &quot;none&quot; as activation</span>\r\n            {<span class=\"hljs-number\">6</span>,\r\n             <span class=\"hljs-string\">&quot;relu&quot;</span>},  <span class=\"hljs-comment\">// Second layer with 6 neurons and &quot;relu&quot; as activation</span>\r\n            {<span class=\"hljs-number\">3</span>, <span class=\"hljs-string\">&quot;sigmoid&quot;</span>}  <span class=\"hljs-comment\">// Third layer with 3 neurons and &quot;sigmoid&quot; as</span>\r\n                            <span class=\"hljs-comment\">// activation</span>\r\n        });\r\n    <span class=\"hljs-comment\">// Printing summary of model</span>\r\n    myNN.<span class=\"hljs-built_in\">summary</span>();\r\n    <span class=\"hljs-comment\">// Training Model</span>\r\n    myNN.<span class=\"hljs-built_in\">fit_from_csv</span>(<span class=\"hljs-string\">&quot;iris.csv&quot;</span>, <span class=\"hljs-literal\">true</span>, <span class=\"hljs-number\">100</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-literal\">false</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">32</span>, <span class=\"hljs-literal\">true</span>);\r\n    <span class=\"hljs-comment\">// Testing predictions of model</span>\r\n    <span class=\"hljs-built_in\">assert</span>(machine_learning::<span class=\"hljs-built_in\">argmax</span>(\r\n               myNN.<span class=\"hljs-built_in\">single_predict</span>({{<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3.4</span>, <span class=\"hljs-number\">1.6</span>, <span class=\"hljs-number\">0.4</span>}})) == <span class=\"hljs-number\">0</span>);\r\n    <span class=\"hljs-built_in\">assert</span>(machine_learning::<span class=\"hljs-built_in\">argmax</span>(\r\n               myNN.<span class=\"hljs-built_in\">single_predict</span>({{<span class=\"hljs-number\">6.4</span>, <span class=\"hljs-number\">2.9</span>, <span class=\"hljs-number\">4.3</span>, <span class=\"hljs-number\">1.3</span>}})) == <span class=\"hljs-number\">1</span>);\r\n    <span class=\"hljs-built_in\">assert</span>(machine_learning::<span class=\"hljs-built_in\">argmax</span>(\r\n               myNN.<span class=\"hljs-built_in\">single_predict</span>({{<span class=\"hljs-number\">6.2</span>, <span class=\"hljs-number\">3.4</span>, <span class=\"hljs-number\">5.4</span>, <span class=\"hljs-number\">2.3</span>}})) == <span class=\"hljs-number\">2</span>);\r\n    <span class=\"hljs-keyword\">return</span>;\r\n}\r\n\r\n<span class=\"hljs-comment\">/**\r\n * @brief Main function\r\n * @returns 0 on exit\r\n */</span>\r\n<span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>{\r\n    <span class=\"hljs-comment\">// Testing</span>\r\n    <span class=\"hljs-built_in\">test</span>();\r\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;\r\n}\r\n"
    }
  },
  "contributors": [
    {
      "name": "Deep Raval",
      "email": "deepraval2905@gmail.com",
      "commits": 4
    }
  ],
  "explanationUrl": {}
}