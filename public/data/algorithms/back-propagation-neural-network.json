{
  "slug": "back-propagation-neural-network",
  "name": "Back Propagation Neural Network",
  "categories": [
    "neuralnetwork"
  ],
  "body": {},
  "implementations": {
    "python": {
      "dir": "neural_network\\back_propagation_neural_network.py",
      "url": "https://github.com/TheAlgorithms/python/tree/master/neural_network\\back_propagation_neural_network.py",
      "code": "<span class=\"hljs-comment\">#!/usr/bin/python</span>\r\n\r\n<span class=\"hljs-string\">&quot;&quot;&quot;\r\n\r\nA Framework of Back Propagation Neural Network（BP） model\r\n\r\nEasy to use:\r\n    * add many layers as you want ！！！\r\n    * clearly see how the loss decreasing\r\nEasy to expand:\r\n    * more activation functions\r\n    * more loss functions\r\n    * more optimization method\r\n\r\nAuthor: Stephen Lee\r\nGithub : https://github.com/RiptideBo\r\nDate: 2017.11.23\r\n\r\n&quot;&quot;&quot;</span>\r\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\r\n<span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt\r\n\r\n\r\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">sigmoid</span>(<span class=\"hljs-params\">x</span>):\r\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span> / (<span class=\"hljs-number\">1</span> + np.exp(-<span class=\"hljs-number\">1</span> * x))\r\n\r\n\r\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DenseLayer</span>:\r\n    <span class=\"hljs-string\">&quot;&quot;&quot;\r\n    Layers of BP neural network\r\n    &quot;&quot;&quot;</span>\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">\r\n        self, units, activation=<span class=\"hljs-literal\">None</span>, learning_rate=<span class=\"hljs-literal\">None</span>, is_input_layer=<span class=\"hljs-literal\">False</span>\r\n    </span>):\r\n        <span class=\"hljs-string\">&quot;&quot;&quot;\r\n        common connected layer of bp network\r\n        :param units: numbers of neural units\r\n        :param activation: activation function\r\n        :param learning_rate: learning rate for paras\r\n        :param is_input_layer: whether it is input layer or not\r\n        &quot;&quot;&quot;</span>\r\n        self.units = units\r\n        self.weight = <span class=\"hljs-literal\">None</span>\r\n        self.bias = <span class=\"hljs-literal\">None</span>\r\n        self.activation = activation\r\n        <span class=\"hljs-keyword\">if</span> learning_rate <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\r\n            learning_rate = <span class=\"hljs-number\">0.3</span>\r\n        self.learn_rate = learning_rate\r\n        self.is_input_layer = is_input_layer\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">initializer</span>(<span class=\"hljs-params\">self, back_units</span>):\r\n        self.weight = np.asmatrix(np.random.normal(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0.5</span>, (self.units, back_units)))\r\n        self.bias = np.asmatrix(np.random.normal(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0.5</span>, self.units)).T\r\n        <span class=\"hljs-keyword\">if</span> self.activation <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:\r\n            self.activation = sigmoid\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">cal_gradient</span>(<span class=\"hljs-params\">self</span>):\r\n        <span class=\"hljs-comment\"># activation function may be sigmoid or linear</span>\r\n        <span class=\"hljs-keyword\">if</span> self.activation == sigmoid:\r\n            gradient_mat = np.dot(self.output, (<span class=\"hljs-number\">1</span> - self.output).T)\r\n            gradient_activation = np.diag(np.diag(gradient_mat))\r\n        <span class=\"hljs-keyword\">else</span>:\r\n            gradient_activation = <span class=\"hljs-number\">1</span>\r\n        <span class=\"hljs-keyword\">return</span> gradient_activation\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward_propagation</span>(<span class=\"hljs-params\">self, xdata</span>):\r\n        self.xdata = xdata\r\n        <span class=\"hljs-keyword\">if</span> self.is_input_layer:\r\n            <span class=\"hljs-comment\"># input layer</span>\r\n            self.wx_plus_b = xdata\r\n            self.output = xdata\r\n            <span class=\"hljs-keyword\">return</span> xdata\r\n        <span class=\"hljs-keyword\">else</span>:\r\n            self.wx_plus_b = np.dot(self.weight, self.xdata) - self.bias\r\n            self.output = self.activation(self.wx_plus_b)\r\n            <span class=\"hljs-keyword\">return</span> self.output\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">back_propagation</span>(<span class=\"hljs-params\">self, gradient</span>):\r\n        gradient_activation = self.cal_gradient()  <span class=\"hljs-comment\"># i * i 维</span>\r\n        gradient = np.asmatrix(np.dot(gradient.T, gradient_activation))\r\n\r\n        self._gradient_weight = np.asmatrix(self.xdata)\r\n        self._gradient_bias = -<span class=\"hljs-number\">1</span>\r\n        self._gradient_x = self.weight\r\n\r\n        self.gradient_weight = np.dot(gradient.T, self._gradient_weight.T)\r\n        self.gradient_bias = gradient * self._gradient_bias\r\n        self.gradient = np.dot(gradient, self._gradient_x).T\r\n        <span class=\"hljs-comment\"># upgrade: the Negative gradient direction</span>\r\n        self.weight = self.weight - self.learn_rate * self.gradient_weight\r\n        self.bias = self.bias - self.learn_rate * self.gradient_bias.T\r\n        <span class=\"hljs-comment\"># updates the weights and bias according to learning rate (0.3 if undefined)</span>\r\n        <span class=\"hljs-keyword\">return</span> self.gradient\r\n\r\n\r\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BPNN</span>:\r\n    <span class=\"hljs-string\">&quot;&quot;&quot;\r\n    Back Propagation Neural Network model\r\n    &quot;&quot;&quot;</span>\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):\r\n        self.layers = []\r\n        self.train_mse = []\r\n        self.fig_loss = plt.figure()\r\n        self.ax_loss = self.fig_loss.add_subplot(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">add_layer</span>(<span class=\"hljs-params\">self, layer</span>):\r\n        self.layers.append(layer)\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">build</span>(<span class=\"hljs-params\">self</span>):\r\n        <span class=\"hljs-keyword\">for</span> i, layer <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(self.layers[:]):\r\n            <span class=\"hljs-keyword\">if</span> i &lt; <span class=\"hljs-number\">1</span>:\r\n                layer.is_input_layer = <span class=\"hljs-literal\">True</span>\r\n            <span class=\"hljs-keyword\">else</span>:\r\n                layer.initializer(self.layers[i - <span class=\"hljs-number\">1</span>].units)\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">summary</span>(<span class=\"hljs-params\">self</span>):\r\n        <span class=\"hljs-keyword\">for</span> i, layer <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(self.layers[:]):\r\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;------- layer %d -------&quot;</span> % i)\r\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;weight.shape &quot;</span>, np.shape(layer.weight))\r\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;bias.shape &quot;</span>, np.shape(layer.bias))\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">train</span>(<span class=\"hljs-params\">self, xdata, ydata, train_round, accuracy</span>):\r\n        self.train_round = train_round\r\n        self.accuracy = accuracy\r\n\r\n        self.ax_loss.hlines(self.accuracy, <span class=\"hljs-number\">0</span>, self.train_round * <span class=\"hljs-number\">1.1</span>)\r\n\r\n        x_shape = np.shape(xdata)\r\n        <span class=\"hljs-keyword\">for</span> round_i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(train_round):\r\n            all_loss = <span class=\"hljs-number\">0</span>\r\n            <span class=\"hljs-keyword\">for</span> row <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(x_shape[<span class=\"hljs-number\">0</span>]):\r\n                _xdata = np.asmatrix(xdata[row, :]).T\r\n                _ydata = np.asmatrix(ydata[row, :]).T\r\n\r\n                <span class=\"hljs-comment\"># forward propagation</span>\r\n                <span class=\"hljs-keyword\">for</span> layer <span class=\"hljs-keyword\">in</span> self.layers:\r\n                    _xdata = layer.forward_propagation(_xdata)\r\n\r\n                loss, gradient = self.cal_loss(_ydata, _xdata)\r\n                all_loss = all_loss + loss\r\n\r\n                <span class=\"hljs-comment\"># back propagation: the input_layer does not upgrade</span>\r\n                <span class=\"hljs-keyword\">for</span> layer <span class=\"hljs-keyword\">in</span> self.layers[:<span class=\"hljs-number\">0</span>:-<span class=\"hljs-number\">1</span>]:\r\n                    gradient = layer.back_propagation(gradient)\r\n\r\n            mse = all_loss / x_shape[<span class=\"hljs-number\">0</span>]\r\n            self.train_mse.append(mse)\r\n\r\n            self.plot_loss()\r\n\r\n            <span class=\"hljs-keyword\">if</span> mse &lt; self.accuracy:\r\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;----达到精度----&quot;</span>)\r\n                <span class=\"hljs-keyword\">return</span> mse\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">cal_loss</span>(<span class=\"hljs-params\">self, ydata, ydata_</span>):\r\n        self.loss = np.<span class=\"hljs-built_in\">sum</span>(np.power((ydata - ydata_), <span class=\"hljs-number\">2</span>))\r\n        self.loss_gradient = <span class=\"hljs-number\">2</span> * (ydata_ - ydata)\r\n        <span class=\"hljs-comment\"># vector (shape is the same as _ydata.shape)</span>\r\n        <span class=\"hljs-keyword\">return</span> self.loss, self.loss_gradient\r\n\r\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">plot_loss</span>(<span class=\"hljs-params\">self</span>):\r\n        <span class=\"hljs-keyword\">if</span> self.ax_loss.lines:\r\n            self.ax_loss.lines.remove(self.ax_loss.lines[<span class=\"hljs-number\">0</span>])\r\n        self.ax_loss.plot(self.train_mse, <span class=\"hljs-string\">&quot;r-&quot;</span>)\r\n        plt.ion()\r\n        plt.xlabel(<span class=\"hljs-string\">&quot;step&quot;</span>)\r\n        plt.ylabel(<span class=\"hljs-string\">&quot;loss&quot;</span>)\r\n        plt.show()\r\n        plt.pause(<span class=\"hljs-number\">0.1</span>)\r\n\r\n\r\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">example</span>():\r\n    x = np.random.randn(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">10</span>)\r\n    y = np.asarray(\r\n        [\r\n            [<span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.4</span>],\r\n            [<span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.3</span>],\r\n            [<span class=\"hljs-number\">0.34</span>, <span class=\"hljs-number\">0.45</span>],\r\n            [<span class=\"hljs-number\">0.67</span>, <span class=\"hljs-number\">0.32</span>],\r\n            [<span class=\"hljs-number\">0.88</span>, <span class=\"hljs-number\">0.67</span>],\r\n            [<span class=\"hljs-number\">0.78</span>, <span class=\"hljs-number\">0.77</span>],\r\n            [<span class=\"hljs-number\">0.55</span>, <span class=\"hljs-number\">0.66</span>],\r\n            [<span class=\"hljs-number\">0.55</span>, <span class=\"hljs-number\">0.43</span>],\r\n            [<span class=\"hljs-number\">0.54</span>, <span class=\"hljs-number\">0.1</span>],\r\n            [<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.5</span>],\r\n        ]\r\n    )\r\n    model = BPNN()\r\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> (<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">20</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">2</span>):\r\n        model.add_layer(DenseLayer(i))\r\n    model.build()\r\n    model.summary()\r\n    model.train(xdata=x, ydata=y, train_round=<span class=\"hljs-number\">100</span>, accuracy=<span class=\"hljs-number\">0.01</span>)\r\n\r\n\r\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:\r\n    example()\r\n"
    }
  },
  "contributors": [
    {
      "name": "Yash Bhardwaj",
      "email": "yashbhardwaj911@gmail.com",
      "commits": 1
    },
    {
      "name": "William Zhang",
      "email": "39932068+WilliamHYZhang@users.noreply.github.com",
      "commits": 1
    },
    {
      "name": "Christian Clauss",
      "email": "cclauss@me.com",
      "commits": 2
    }
  ],
  "explanationUrl": {}
}